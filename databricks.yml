# --- GENERADO AUTOMÁTICAMENTE POR JINJA2 ---
# Bundle para el framework modular DLT

bundle:
  name: "framework-dlt-generado"

workspace:
  root_path: "/Users/${workspace.current_user.userName}/framework-dlt/${bundle.name}"

# Lista los artefactos a desplegar
artifacts:
  # El módulo de helpers
  - path: "src/dlt_helpers.py"
    destination: "/${bundle.target}/src"
  # Los pipelines generados (RUTA ACTUALIZADA)
  - path: "pipelines_generadas/"
    destination: "/${bundle.target}/pipelines_generadas"

targets:
  dev:
    mode: development
    default: true
    workspace:
      pass
    
    resources:
      pipelines:
        dlt_df1_persons_employees:
          name: "DLT - df1_persons_employees"
          development: true
          libraries:
            # Apunta al notebook DLT en la carpeta de destino (RUTA ACTUALIZADA)
            - notebook: { path: "/${bundle.target}/pipelines_generadas/dlt_df1_persons_employees.py" }
          # ¡IMPORTANTE! Ajusta esto a tu Unity Catalog
          storage: "/Volumes/workspace/elt_modular_dlt/dlt_storage/df1_persons_employees"
          target: "workspace"
          schema: "elt_modular_dlt"
        dlt_df2_polizas:
          name: "DLT - df2_polizas"
          development: true
          libraries:
            # Apunta al notebook DLT en la carpeta de destino (RUTA ACTUALIZADA)
            - notebook: { path: "/${bundle.target}/pipelines_generadas/dlt_df2_polizas.py" }
          # ¡IMPORTANTE! Ajusta esto a tu Unity Catalog
          storage: "/Volumes/workspace/elt_modular_dlt/dlt_storage/df2_polizas"
          target: "workspace"
          schema: "elt_modular_dlt"

      jobs:
        mega_job_all_pipelines:
          name: "Mega Job - Todos los Dataflows"
          tasks:
            - task_key: "run_dlt_df1_persons_employees"
              description: "Ejecuta el pipeline DLT para df1_persons_employees"
              pipeline_task:
                pipeline_id: "${resources.pipelines.dlt_df1_persons_employees.id}"
              # Opcional: descomenta para ejecutar en secuencia
              #             - task_key: "run_dlt_df2_polizas"
              description: "Ejecuta el pipeline DLT para df2_polizas"
              pipeline_task:
                pipeline_id: "${resources.pipelines.dlt_df2_polizas.id}"
              # Opcional: descomenta para ejecutar en secuencia
              #               # depends_on:
              #   - task_key: "run_dlt_df1_persons_employees"
              # 
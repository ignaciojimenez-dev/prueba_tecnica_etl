# --- PLANTILLA YML.J2 (CORREGIDA) ---
# Usa 'sync.include:' y la ruta de tu workspace

bundle:
  name: "framework-dlt-generado"

# ¡Ruta REAL de tu proyecto en Databricks Repos!
workspace:
  root_path: "/Workspace/Users/ignaqwert00@gmail.com/prueba_tecnica_etl"

# ¡LA CORRECCIÓN ESTÁ AQUÍ!
# Usamos 'sync.include' para SINCRONIZAR ficheros .py
sync:
  include:
    - "src/dlt_helpers.py"
    - "pipelines_generadas/*.py" # Incluye todos los .py generados

targets:
  dev:
    mode: development
    default: true
    workspace: {} # Limpio y vacío
    
    resources:
      pipelines:
        {% for df in dataflows %}
        dlt_{{ df.name }}:
          name: "DLT - {{ df.name }}"
          development: true
          libraries:
            # El path es ahora relativo al root_path de arriba
            - notebook: { path: "pipelines_generadas/dlt_{{ df.name }}.py" }
          storage: "/Volumes/workspace/elt_modular_dlt/dlt_storage/{{ df.name }}"
          target: "workspace"
          schema: "elt_modular_dlt"
        {% endfor %}

      jobs:
        mega_job_all_pipelines:
          name: "Mega Job - Todos los Dataflows"
          tasks:
            {% for df in dataflows %}
            - task_key: "run_dlt_{{ df.name }}"
              description: "Ejecuta el pipeline DLT para {{ df.name }}"
              pipeline_task:
                pipeline_id: "${resources.pipelines.dlt_{{ df.name }}.id}"
              # Lógica de secuencia (Corregida)
              {% if not loop.first %}
              depends_on:
                - task_key: "run_dlt_{{ loop.previtem.name }}"
              {% endif %}
            {% endfor %}
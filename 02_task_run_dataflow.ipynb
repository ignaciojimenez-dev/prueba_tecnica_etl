{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5102962f",
   "metadata": {},
   "source": [
    "Tarea 2 For-each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbc6ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- CELDA DE PRUEBA MANUAL ---\n",
    "# (Borra esta celda antes de ponerla en el Job final)\n",
    "\n",
    "# 1. Pega la configuración COMPLETA Y VÁLIDA\n",
    "test_config_json = \"\"\"\n",
    "{\n",
    "  \"name\": \"df1\",\n",
    "  \"sources\": [\n",
    "    {\n",
    "      \"name\": \"person_inputs\",\n",
    "      \"path\": \"/Volumes/workspace/prueba_tecnica/data/inputs/events/person/*\",\n",
    "      \"format\": \"JSON\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"employees_inputs\",\n",
    "      \"path\": \"/Volumes/workspace/prueba_tecnica/data/inputs/events/employees/*\",\n",
    "      \"format\": \"JSON\"\n",
    "    }\n",
    "  ],\n",
    "  \"transformations\": [\n",
    "    {\n",
    "      \"name\": \"validation\",\n",
    "      \"type\": \"validate_fields\",\n",
    "      \"params\": { \n",
    "        \"input\": \"person_inputs\", \n",
    "        \"validations\": [\n",
    "          {\n",
    "            \"field\": \"office\",\n",
    "            \"validations\": [\"notEmpty\"]\n",
    "          },\n",
    "          {\n",
    "            \"field\": \"age\",\n",
    "            \"validations\": [\"notNull\"]\n",
    "          }\n",
    "        ] \n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ok_with_date\",\n",
    "      \"type\": \"add_fields\",\n",
    "      \"params\": { \n",
    "        \"input\": \"validation_ok\", \n",
    "        \"addFields\": [\n",
    "          {\n",
    "            \"name\": \"dt\",\n",
    "            \"function\": \"current_timestamp\"\n",
    "          }\n",
    "        ] \n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"sinks\": [\n",
    "    {\n",
    "      \"input\": \"ok_with_date\",\n",
    "      \"name\": \"raw_ok\",\n",
    "      \"path\": \"/Volumes/workspace/prueba_tecnica/silver/person\",\n",
    "      \"format\": \"DELTA\",\n",
    "      \"saveMode\": \"OVERWRITE\"\n",
    "    },\n",
    "    {\n",
    "      \"input\": \"validation_ko\",\n",
    "      \"name\": \"raw_ko\",\n",
    "      \"path\": \"/Volumes/workspace/prueba_tecnica/discards/person\",\n",
    "      \"format\": \"DELTA\",\n",
    "      \"saveMode\": \"OVERWRITE\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 2. Esto simula lo que hace el Job:\n",
    "dbutils.widgets.text(\"dataflow_config_json\", test_config_json)\n",
    "print(\"Widget 'dataflow_config_json' rellenado con datos de prueba VÁLIDOS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac8dab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Obtener la raíz del proyecto (en Repos, os.getcwd() es la raíz)\n",
    "project_root = os.getcwd()\n",
    "\n",
    "# 2. Añadir la raíz al path de Python\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "  \n",
    "  \n",
    "# Databricks Notebook: 02_task_run_dataflow\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# IMPORTANTE: Asume que tu código 'src' está disponible\n",
    "# (ej. porque estás usando Databricks Repos)\n",
    "from src import orchestrator\n",
    "from src import utils\n",
    "\n",
    "# Configuración del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# --- 1. Definir el Widget de Entrada ---\n",
    "# Este widget recibirá la configuración de UN solo dataflow.\n",
    "# El Job \"For-Each\" de Databricks rellenará este widget.\n",
    "# IMPORTANTE: Databricks pasa los diccionarios como un string de JSON.\n",
    "dbutils.widgets.text(\"dataflow_config_json\", \"{}\", \"Configuración del Dataflow (JSON String)\")\n",
    "\n",
    "# --- 2. Leer el Widget ---\n",
    "dataflow_json_string = dbutils.widgets.get(\"dataflow_config_json\")\n",
    "log.info(\"Tarea 2 (For-Each) iniciada.\")\n",
    "\n",
    "try:\n",
    "    # --- 3. Convertir el string JSON de vuelta a un diccionario ---\n",
    "    dataflow_config = json.loads(dataflow_json_string)\n",
    "    \n",
    "    if not dataflow_config or 'name' not in dataflow_config:\n",
    "        raise ValueError(\"Configuración de dataflow vacía o inválida recibida.\")\n",
    "        \n",
    "    dataflow_name = dataflow_config.get(\"name\")\n",
    "    log.info(f\"Procesando dataflow: {dataflow_name}\")\n",
    "\n",
    "    # --- 4. Obtener Spark y Ejecutar el Framework ---\n",
    "    \n",
    "    # utils.get_spark_session() detectará que está en Databricks\n",
    "    # y simplemente obtendrá la sesión 'spark' existente.\n",
    "    spark = utils.get_spark_session()\n",
    "    \n",
    "    # ¡Aquí es donde se llama a todo tu código de 'src' (orchestrator, writers, etc.)!\n",
    "    orchestrator.run_single_dataflow(spark, dataflow_config)\n",
    "    \n",
    "    log.info(f\"Dataflow {dataflow_name} completado exitosamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    log.error(f\"Error fatal durante la ejecución del dataflow: {e}\", exc_info=True)\n",
    "    # Lanzamos el error para que la Tarea del Job de Databricks falle\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
